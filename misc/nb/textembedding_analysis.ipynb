{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^_^ Using the right lm model!!!\n",
      "Language model Loaded!!!^_^\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/share/project/yfl/codebase/stable_diffusion_2.0/stablediffusion/')\n",
    "from lm.dcn_clip import DCNCLIP30M1024\n",
    "from ldm.modules.encoders.modules import FrozenOpenCLIPEmbedder\n",
    "\n",
    "os.environ[\"CUDA_VESIBLE_DEVICES\"] = '7'\n",
    "\n",
    "altclip = DCNCLIP30M1024().to(\"cuda\")\n",
    "openclip = FrozenOpenCLIPEmbedder().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample出10K的prompts\n",
    "\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "n = 1000\n",
    "\n",
    "#### samle 10000个图文对\n",
    "path = '/share/project/yfl/codebase/nb/laion6plus/part_1.json'\n",
    "with open(path, 'r') as fn:\n",
    "    d = json.load(fn)\n",
    "\n",
    "\n",
    "samples = random.sample(d, n)\n",
    "\n",
    "texts = []\n",
    "for sample in samples:\n",
    "    texts.append(sample['source_caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib import tzip\n",
    "\n",
    "def compared_altwithopen(texts_en, texts_other=None):\n",
    "    loss_func  = torch.nn.MSELoss()\n",
    "    loss_result_min = []\n",
    "\n",
    "    if texts_other:\n",
    "        for text_en, text_other in tzip(texts_en, texts_other, desc=\"Evaluating:\"):\n",
    "        \n",
    "            loss_result = []\n",
    "            emb1 = altclip.encode(text_other)\n",
    "            emb2 = openclip.encode(text_en)\n",
    "\n",
    "            for token in emb2[0]:\n",
    "                cls = emb1[0][0].to(\"cuda\")\n",
    "                loss_result.append(loss_func(token, cls))\n",
    "            loss_result_min.append(min(loss_result))\n",
    "    else:\n",
    "        for text in tqdm(texts_en, desc=\"Evaluating:\"):\n",
    "            \n",
    "            loss_result = []\n",
    "            emb1 = altclip.encode(text)\n",
    "            emb2 = openclip.encode(text)\n",
    "\n",
    "            for token in emb2[0]:\n",
    "                cls = emb1[0][0].to(\"cuda\")\n",
    "                loss_result.append(loss_func(token, cls))\n",
    "            loss_result_min.append(min(loss_result))\n",
    "             \n",
    "    print(\"Average MSE: {}\".format(sum(loss_result_min)/len(loss_result_min)))\n",
    "\n",
    "def compared_altwithalt(texts1, texts2):\n",
    "    loss_func  = torch.nn.MSELoss()\n",
    "    loss_result = []\n",
    "\n",
    "    for text1, text2 in tqdm(zip(texts1, texts2), desc=\"Evaluating:\"):\n",
    "        \n",
    "        emb1 = altclip.encode(text1)\n",
    "        emb2 = altclip.encode(text2)\n",
    "\n",
    "        cls1 = emb1[0][0].to(\"cuda\")\n",
    "        cls2 = emb2[0][0].to(\"cuda\")\n",
    "        loss_result.append(loss_func(cls1, cls2))\n",
    "        \n",
    "    print(\"Average MSE: {}\".format(sum(loss_result)/len(loss_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./text_embedding_analysis/texts_dict.json\", 'r') as fn:\n",
    "    d1 = json.load(fn)\n",
    "\n",
    "with open(\"./text_embedding_analysis/texts_dict_ar_AR.json\", 'r') as fn:\n",
    "    d2 = json.load(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts1 = []\n",
    "texts2 = []\n",
    "for it in d1:\n",
    "    texts1.append(it[\"source_caption\"])\n",
    "for it in d2:\n",
    "    texts2.append(it[\"target_caption\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bdad17ac6f1438980d5f24ffc7bdd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating::   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 0.33988305926322937\n"
     ]
    }
   ],
   "source": [
    "compared_altwithopen(texts_en=texts1, texts_other=texts2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/share/project/yfl/codebase/stable_diffusion_2.0/stablediffusion/nb/validation/gt.json', 'r') as fn:\n",
    "    data = json.load(fn)\n",
    "\n",
    "exp_name = 'sd2.1'\n",
    "# 存储对应的json文件\n",
    "result = []\n",
    "for datum in data:\n",
    "    caption = datum['source_caption']\n",
    "    original_dir = datum['image']\n",
    "    file_name = original_dir.split(\"/\")[-1]\n",
    "    result.append(\n",
    "        {\n",
    "            \"caption\": caption,\n",
    "            \"image\": '/share/project/yfl/codebase/stable_diffusion_2.0/stablediffusion/nb/validation/generate_imgs/' + exp_name + '/' + file_name,\n",
    "        }\n",
    "    )\n",
    "\n",
    "with open('./validation/' + exp_name + '.json', 'w') as fn:\n",
    "    json.dump(result, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
